---
title: "Tree models"
author: "Charlotte Fowler"
date: "5/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rsample)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(pROC)
```


```{r}
set.seed(1)

data_cv = data %>% mutate(
  five_stars_cat = ifelse(five_stars == "1","yes", "no" ), 
  five_stars_cat = as.factor(five_stars_cat))


```


#Tree 

```{r}
set.seed(1)
tree1 <- rpart(formula = five_stars_cat ~ neighbourhood_group + room_type + price + number_of_reviews + reviews_per_month + availability_365, 
               data = train_data,
               control = rpart.control(cp = 0.0003))

cp_table = broom::tidy(printcp(tree1))

min_xerror = min(cp_table$xerror)

best_cp = cp_table %>% 
  filter(xerror == min_xerror) %>% 
  pull(CP)

plotcp(tree1)

tree_1se <- prune(tree1, cp = best_cp)

rpart.plot(tree_1se)

train_pred_tree = predict(tree_1se, newdata = train_data, type="prob")

roc.lda <- roc(train_data$five_stars,
               train_pred_tree[,2], 
               levels = c("0", "1"))

```
From the 1-SE rule, we select the tree with 2 splits, as it produces the lowest xerror. This model produces a train AUC of 0.8448.  



# Random Forest

```{r}
set.seed(1)
random_forest <- randomForest(five_stars_cat ~ neighbourhood_group + room_type + price + number_of_reviews + reviews_per_month + availability_365, 
                              data = train_data, mtry = 3) # double check this mtry value

train_pred_random_forest = predict(random_forest, newdata = train_data, type="prob")

roc.lda <- roc(train_data$five_stars,
               train_pred_random_forest[,2], 
               levels = c("0", "1"))
```
The random forest method generates a test error of 0.115. 

AUC on test is 0.9996


```{r}
#Takes forever, to be deleted ?? 
ctrl <- trainControl(method = "repeatedcv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

rf.grid <- expand.grid(mtry = 1:6,
                       splitrule = "gini",
                       min.node.size = 1:6)
set.seed(1)
rf.fit <- train(five_stars_cat ~ neighbourhood_group + room_type + price + 
                  number_of_reviews + reviews_per_month + availability_365,
                data = train_data,
                method = "ranger",
                tuneGrid = rf.grid,
                metric = "ROC",
                trControl = ctrl)

test_pred_random_forest2 = predict(random_forest, newdata = test_data, type="class")
confusionMatrix(data = test_pred_random_forest2, reference = test_data$five_stars_cat)

train_pred_random_forest = predict(rf.fit, newdata = train_data, type="prob")

roc.lda <- roc(train_data$five_stars,
               train_pred_random_forest[,2], 
               levels = c("0", "1"))

```
train AUC of 0.9644

# Bagging
```{r}
set.seed(1)
bagging <- randomForest(five_stars_cat ~ neighbourhood_group + room_type + price + 
                          number_of_reviews + reviews_per_month + availability_365, 
                        data = train_data, mtry = 8)

train_pred_bagging = predict(bagging, newdata = train_data, type="prob")

roc.lda <- roc(train_data$five_stars,
               train_pred_random_forest[,2], 
               levels = c("0", "1"))

```

AUC of .9644

# Boosting

```{r}
gbmB.grid <- expand.grid(n.trees = c(2000,3000,4000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.001,0.003,0.005),
                         n.minobsinnode = 1)
set.seed(1)
gbmB.fit <- train(five_stars_cat ~ neighbourhood_group + room_type + price + 
                          number_of_reviews + reviews_per_month + availability_365,
                  data = train_data,
                  tuneGrid = gbmB.grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "bernoulli",
                  metric = "ROC",
                  verbose = FALSE)

train_pred_boosting = predict(gbmB.fit, newdata = train_data, type="prob")

roc.lda <- roc(train_data$five_stars,
               train_pred_boosting[,2], 
               levels = c("0", "1"))

```



AUC 0.9391


